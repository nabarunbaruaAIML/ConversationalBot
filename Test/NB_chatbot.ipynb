{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\" I am a large language model trained by Mistral AI. I was designed to assist with a wide range of tasks such as answering questions, helping generate text, summarizing information, and much more. I can process vast amounts of data and provide responses in multiple languages. My goal is to make it easier for people to find answers, create content, and understand complex topics. While I don't have personal experiences or emotions like humans, I am programmed to learn and adapt over time based on interactions with users like you.\", response_metadata={'model': 'mistral:instruct', 'created_at': '2024-07-18T16:31:45.074578Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 1988209292, 'load_duration': 8619875, 'prompt_eval_count': 15, 'prompt_eval_duration': 240477000, 'eval_count': 107, 'eval_duration': 1736582000}, id='run-dbdcbd1b-6f92-4794-b9a2-76e40bf1429e-0')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from langchain_community.llms import Ollama\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv() ## aloading all the environment variable\n",
    "\n",
    "# llm = Ollama(model='mistral:instruct')\n",
    "llm = ChatOllama(model='mistral:instruct')\n",
    "# llm = ChatOllama(model=\"gemma:2b\")\n",
    "# llm = ChatOllama(model=\"gemma2:9b\")\n",
    "llm.invoke('<s>[INST] tell me about yourself? [/INST]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store={}\n",
    "\n",
    "def get_session_history(session_id:str)->BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id]=ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history=RunnableWithMessageHistory(llm,get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat10\"}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\" Hello Nabarun, it's nice to meet you! As a Chief AI Engineer, I imagine you have a lot of interesting work. How can I assist you today? Are there any specific questions or topics related to artificial intelligence that you would like to discuss?\", response_metadata={'model': 'mistral:instruct', 'created_at': '2024-07-18T15:48:30.488546Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 1172446500, 'load_duration': 13004375, 'prompt_eval_count': 22, 'prompt_eval_duration': 243184000, 'eval_count': 57, 'eval_duration': 914085000}, id='run-9674e91c-9a4c-446e-8702-8c3f23d6497e-0')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage,SystemMessage\n",
    "response=with_message_history.invoke(\n",
    "    # [\n",
    "        # SystemMessage(content=\"<s>[INST] You are a helpful AI Bot. In a case if you don't know the answer then tell you don't know it[/INST]<s>\"),\n",
    "    #  HumanMessage(content=\"[INST]Hi , My name is Nabarun and I am a Senior Data Scientist[/INST]\")],\n",
    "    # [HumanMessage(content=\"Hi , My name is Nabarun and I am a Chief AI Engineer\")],\n",
    "    [   \n",
    "        # SystemMessage(content=\"You are a helpful Chatbot who answers users request. But don't answer harmful content\"),\n",
    "        HumanMessage(content=\"Hi , My name is Nabarun and I am a Chief AI Engineer\")\n",
    "    ],\n",
    "    config=config\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\" Your name is Nabarun, as mentioned earlier in our conversation. Is there anything specific you'd like to know or discuss about artificial intelligence? I'm here to help!\", response_metadata={'model': 'mistral:instruct', 'created_at': '2024-07-18T15:48:32.299055Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 844336875, 'load_duration': 8883375, 'prompt_eval_count': 89, 'prompt_eval_duration': 210344000, 'eval_count': 39, 'eval_duration': 619632000}, id='run-7599de75-21e1-4995-95f8-d0f7520cf3b5-0')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=with_message_history.invoke(\n",
    "    # [\n",
    "        # SystemMessage(content=\"<s>[INST] You are a helpful AI Bot. In a case if you don't know the answer then tell you don't know it[/INST]<s>\"),\n",
    "        # HumanMessage(content=\"[INST]what is my name[/INST]\")],\n",
    "    # [HumanMessage(content=\"Hi , what is my name\")],\n",
    "    [   \n",
    "        # SystemMessage(content=\"You are a helpful Chatbot who answers users request. But don't answer harmful content\"),\n",
    "        HumanMessage(content=\"Hi , what is my name\")\n",
    "    ],\n",
    "    config=config\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage,SystemMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# prompt=ChatPromptTemplate.from_messages(\n",
    "#     [\n",
    "#         (\"system\",\"You are a helpful assistant.Amnswer all the question to the nest of your ability\"),\n",
    "#         MessagesPlaceholder(variable_name=\"messages\")\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# prompt=ChatPromptTemplate.from_template(f\"\"\"<s>[INST]You are helpful chatbot who answers all the question as best of your ability.\\n\\n{MessagesPlaceholder(variable_name=\"messages\")}[/INST]\"\"\")\n",
    "prompt=ChatPromptTemplate.from_template(\"\"\"<s>[INST]You are helpful chatbot who answers all the question as best of your ability. First Analysis the complete Message and only answer to the Question being asked and do not try add extra information apart what is being asked.\\n\\nMessage:{message}[/INST]\"\"\")\n",
    "parser = StrOutputParser()\n",
    "chain=prompt|llm |parser\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Hello Nabarun, it's nice to meet you! How can I help you today? If you have any questions or need assistance with something, feel free to ask!\""
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chain.invoke({\"message\":[HumanMessage(content=\"Hi My name is Nabarun\")]})\n",
    "\n",
    "chain.invoke({\"message\":\"Hi My name is Nabarun\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Hello Nabarun, it's nice to meet you! As a Senior Data Scientist at Wipro, I can imagine that you work with a variety of fascinating data sets. If there's something specific about your role or the field of data science you'd like to discuss, feel free to ask!\""
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "# config={\"configurable\":{\"session_id\":\"chat10\"}}\n",
    "store={}\n",
    "\n",
    "def get_session_history(session_id:str)->BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id]=ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history=RunnableWithMessageHistory(chain,\n",
    "                                                get_session_history,\n",
    "                                                input_messages_key=\"message\")\n",
    "\n",
    "config = {\"configurable\": {\"session_id\": \"chat9\"}}\n",
    " \n",
    "\n",
    "response=with_message_history.invoke(\n",
    "    {\"message\":\"Hi My name is Nabarun and I am Senior Data Scientist at Wipro\"},\n",
    "    config=config\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Your name is Nabarun.'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=with_message_history.invoke(\n",
    "    {\"message\":\"what is my name\"},\n",
    "    config=config\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Your designation is Senior Data Scientist.'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=with_message_history.invoke(\n",
    "    {\"message\":\"what is my Designation\"},\n",
    "    config=config\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage,trim_messages,AIMessage,HumanMessage\n",
    "\n",
    "trimmer=trim_messages(\n",
    "    max_tokens=100,\n",
    "    strategy=\"last\",\n",
    "    token_counter=llm,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on=\"human\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"you're a good assistant\"),\n",
       " HumanMessage(content=\"hi! I'm bob\"),\n",
       " AIMessage(content='hi!'),\n",
       " HumanMessage(content='I like vanilla ice cream'),\n",
       " AIMessage(content='nice'),\n",
       " HumanMessage(content='whats 2 + 2'),\n",
       " AIMessage(content='4'),\n",
       " HumanMessage(content='thanks'),\n",
       " AIMessage(content='no problem!'),\n",
       " HumanMessage(content='having fun?'),\n",
       " AIMessage(content='yes!')]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messagess = [\n",
    "    SystemMessage(content=\"you're a good assistant\"),\n",
    "    HumanMessage(content=\"hi! I'm bob\"),\n",
    "    AIMessage(content=\"hi!\"),\n",
    "    HumanMessage(content=\"I like vanilla ice cream\"),\n",
    "    AIMessage(content=\"nice\"),\n",
    "    HumanMessage(content=\"whats 2 + 2\"),\n",
    "    AIMessage(content=\"4\"),\n",
    "    HumanMessage(content=\"thanks\"),\n",
    "    AIMessage(content=\"no problem!\"),\n",
    "    HumanMessage(content=\"having fun?\"),\n",
    "    AIMessage(content=\"yes!\"),\n",
    "]\n",
    "trimmer.invoke(messagess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['messages'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['messages'], template='<s>[INST]You are helpful chatbot who answers all the question as best of your ability. First Analysis the complete Message and only answer to the Question being asked and do not try add extra information apart what is being asked.\\n\\nMessage:{messages}[/INST]'))])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage,SystemMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    " \n",
    "prompt=ChatPromptTemplate.from_template(\"\"\"<s>[INST]You are helpful chatbot who answers all the question as best of your ability. First Analysis the complete Message and only answer to the Question being asked and do not try add extra information apart what is being asked.\\n\\nMessage:{messages}[/INST]\"\"\")\n",
    "prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "chain=(\n",
    "        RunnablePassthrough.assign(messages=itemgetter(\"messages\")|trimmer)\n",
    "        |prompt\n",
    "        |llm\n",
    "        |parser\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The user Bob mentioned that he likes vanilla ice cream.'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\n",
    "                \"messages\":messagess +[\n",
    "                                        HumanMessage(content=\"Hi what ice cream I like\")\n",
    "                                    ]\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Hello Nabarun, it's nice to meet you! As a Senior Data Scientist at Wipro, I assume you work with large amounts of data and employ various machine learning techniques to extract valuable insights. How may I assist you today?\""
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "# config={\"configurable\":{\"session_id\":\"chat10\"}}\n",
    "store={}\n",
    "\n",
    "def get_session_history(session_id:str)->BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id]=ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history=RunnableWithMessageHistory(chain,\n",
    "                                                get_session_history,\n",
    "                                                input_messages_key=\"messages\")\n",
    "\n",
    "config = {\"configurable\": {\"session_id\": \"chat9\"}}\n",
    " \n",
    "\n",
    "# response=with_message_history.invoke(\n",
    "#     {\"message\":\"Hi My name is Nabarun and I am Senior Data Scientist at Wipro\"},\n",
    "#     config=config\n",
    "# )\n",
    "\n",
    "# response\n",
    "\n",
    "response=with_message_history.invoke(\n",
    "    {\"messages\":\"Hi My name is Nabarun and I am Senior Data Scientist at Wipro\"},\n",
    "    \n",
    "    config=config\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Your name is Nabarun.'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=with_message_history.invoke(\n",
    "    {\"messages\":\"what is my name\"},\n",
    "    config=config\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Your designation is Senior Data Scientist.'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=with_message_history.invoke(\n",
    "    {\"messages\":\"what is my Designation\"},\n",
    "    config=config\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Your name is Nabarun. I've answered this question in the previous response.\""
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=with_message_history.invoke(\n",
    "    {\"messages\":\"what is my name\"},\n",
    "    config=config\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat9': InMemoryChatMessageHistory(messages=[HumanMessage(content='Hi My name is Nabarun and I am Senior Data Scientist at Wipro'), AIMessage(content=\" Hello Nabarun, nice to meet you! It's great that you are a Senior Data Scientist at Wipro. If you have any questions related to data science or need assistance with your work, feel free to ask.\"), HumanMessage(content='what is my name'), AIMessage(content=' Your name is Nabarun.'), HumanMessage(content='what is my Designation'), AIMessage(content=' Your designation is Senior Data Scientist.'), HumanMessage(content='what is my name'), AIMessage(content=' Your name is Nabarun.')])}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Your designation is Senior Data Scientist.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=with_message_history.invoke(\n",
    "    {\"messages\":\"what is my Designation\"},\n",
    "    config=config\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
